# unqork-api-test-pcp

Unqork's Platform Control Plane coding interview challenge.

## Background

Unqork needs a new minimal API endpoint for creating and tracking S3 buckets ([`s3`](./app/models/s3.js)).

>NOTE you may alternatively complete this assignment in any other mainstream general purpose programming language. There will be no provided repo skeleton in such cases. Please adhere to the same structure and testing standards.

## Requirements

1. This endpoint should be [RESTful](https://tools.ietf.org/html/rfc7231) and should use the appropriate [HTTP methods](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods).
2. Since this API is meant to be minimal, any external dependencies should be limited.
3. Resources should be represented by [JSON](https://www.json.org) payloads and stored in a MongoDB collection using [mongoose](https://mongoosejs.com) for modeling and validations.
4. Testing should aim for 100% code coverage, with any exceptions noted and why. Please mock the `aws-sdk/s3` methods, no need for integration tests.
5. Code style should follow the installed and configured linting package as well as existing patterns for code structure.
6. All code will be under the [`app/`](./app) directory.

## In Scope

The new endpoint will be `/s3`. It will be a resource that exposes access to typical DB CRUD operations as well as performing the requisite API call(s) to AWS in order to complete the requested operations:

You will be using the provided aws-sdk for nodejs.

* Creating a new `s3` bucket and internally track it
  * be sure to handle errors such as an `s3` bucket with the same name already existing, (`400` error, with an explanation)
* Retrieving a list of internally tracked `s3` buckets
* Retrieving a particular internally tracked `s3` bucket
* Updating a particular internally tracked `s3` bucket
* Deleting a tracked `s3` bucket
  * For this exersise there is no need to ensure that all objects in the bucket are also deleted, (`400` error, with an explanation)

A `s3` bucket database entry will have 5 properties:

* name (string; required; unique)
* account_id (string; required; AWS account id owning the bucket)
* versioning (bool; required; determines if versioning is enabled on the bucket)
* created (timestamp; cannot be provided or updated in request, set at creation of document)
* modified (timestamp; cannot be provided in request, set at creation and modification of document)

## Out of Scope

Anything not explicitly stated as in scope.

------

## Instructions

1. `yarn`
2. `yarn test` to run the tests.
3. `yarn test -- --coverage` to generate code coverage results.
4. Alternatively use `yarn run watch` to run tests with code coverage while coding for red/green development.
5. `yarn run submit` to generate a `submission.zip` that will be submitted to your talent representative.

## Notes

* Existing code should demonstrate expected code and testing patterns. However, if any questions arise, please reach out for clarification. Also, if you feel a better pattern is appropriate, please feel free to use it but document why you choose to.
* There is an [`.env.`](./.env) file that specifies `PORT` and `MONGO_URL`. You should only need to set `MONGO_URL` if you want to run the server on its own (`npm run start`).
* Existing code and tests are mostly undocumented and only stubbed out in certain circumstances. Please document and be thorough with your code and tests.

## Expectations

* Completion time should be approximately 2-3 hours or less but please finish all requirements.
* If your schedule permits, please complete any or all of the bonuses below.
* Annotate code and tests as necessary for clarity.

## Bonuses

Please complete any or all of these additional requirements if time permits. Please follow the testing guidance for any attempted bonuses.

* Asynchronously create the bucket
* When querying for a list of `s3` buckets, provide a query parameter, `filter`, to filter the returned list. This should be a general purpose parameter to allow filtering by one or more fields.
* When querying for a single `s3` bucket, additionally include the information provided by the AWS API under the `aws-data` field
* Add an autogenerated documentation process for the API. Pick your favorite that aligns best with the code structure.

## HINT

[aws-sdk/s3 docs](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-creating-buckets.html)
